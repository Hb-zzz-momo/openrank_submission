# backend/api/opendigger.py
"""
æœ¬æ–‡ä»¶ = æ‰€æœ‰åç«¯æ¥å£çš„è“å›¾ï¼ˆBlueprintï¼‰
è·¯å¾„ç»Ÿä¸€ä»¥ /api å¼€å¤´ï¼Œä¾‹å¦‚ï¼š
  /api/platforms
  /api/entities/github
  /api/data/github/pytorch/pytorch/openrank
  /api/llm/summary
  /api/llm/report
"""

from flask import Blueprint, jsonify, request
from pathlib import Path
import json
import requests
import warnings
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
from datetime import datetime, timedelta
from extensions import db
from models import MetricSeries

# âœ… å¯¼å…¥ç»Ÿä¸€çš„å·¥å…·å‡½æ•°
from metric_utils import mean as _mean, std_population as _std_pop, tail_n_values, calculate_health_score
from rate_limiter import rate_limit
# OpenAI å®¢æˆ·ç«¯
try:
    from openai import OpenAI  # openai>=1.x
    openai_client = OpenAI()   # ä¼šè‡ªåŠ¨è¯» OPENAI_API_KEY ç¯å¢ƒå˜é‡
except Exception:
    openai_client = None

# å¯¼å…¥ä½ è‡ªå·±çš„å…ƒæ•°æ®æ¨¡å—
import metadata as meta

# ==== åŸºç¡€è·¯å¾„ ====
BASE_DIR = Path(__file__).resolve().parent.parent  # backend/
DATA_DIR = BASE_DIR / "data"
DATA_DIR.mkdir(exist_ok=True)

CONFIG_FILE = BASE_DIR / "config.json"

# å†…å­˜ç¼“å­˜ï¼Œé¿å…é¢‘ç¹åˆ·æ–°é¡µé¢æ—¶æ¯æ¬¡éƒ½é‡ç®—
_LLM_SUMMARY_CACHE = {"ts": None, "data": None}
LLM_CACHE_TTL_SECONDS = 300  # 5åˆ†é’Ÿ


# âœ… è¾…åŠ©å‡½æ•°ï¼šè·å–æœ€è¿‘12ä¸ªæœˆæ•°æ®ï¼ˆä½¿ç”¨ç»Ÿä¸€å·¥å…·ï¼‰
def _tail12_values(records):
    """å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°"""
    return tail_n_values(records, n=12, month_key="month", value_key="count")


def compute_llm_summary_from_db():
    """
    ä»æ•°æ®åº“è®¡ç®— LLM ç”Ÿæ€æ±‡æ€»æ•°æ®
    ä¼˜åŒ–ï¼šä½¿ç”¨æ‰¹é‡æŸ¥è¯¢æ›¿ä»£ N+1 æŸ¥è¯¢ï¼Œæ˜¾è‘—æå‡æ€§èƒ½
    """
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            config = json.load(f)
    except Exception as e:
        raise ApiException(500, f"è¯»å– config.json å¤±è´¥: {e}")

    repos = config.get("repositories", [])
    
    if not repos:
        raise ApiException(404, "é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰å®šä¹‰ä»»ä½•ä»“åº“")

    # âœ… ä¼˜åŒ–ï¼šä¸€æ¬¡æ€§æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰éœ€è¦çš„ MetricSeriesï¼ˆåªæ‰§è¡Œ 1 æ¬¡ SQLï¼‰
    all_series = MetricSeries.query.filter(
        MetricSeries.metric.in_(["openrank", "activity"])
    ).all()
    
    # âœ… æ„å»ºå†…å­˜ç´¢å¼•ï¼š{(platform, entity, repo, metric): row}
    # åç»­æŸ¥æ‰¾æ—¶é—´å¤æ‚åº¦ O(1)ï¼Œä¸å†è§¦å‘ SQL
    series_map = {}
    for row in all_series:
        key = (row.platform, row.entity, row.repo, row.metric)
        series_map[key] = row
    
    summary_items = []

    for repo_info in repos:
        platform = repo_info["platform"]
        org = repo_info["org"]
        repo = repo_info["repo"]
        category = repo_info.get("category", "unknown")
        repo_key = f"{platform}/{org}/{repo}"

        # âœ… ä»å†…å­˜ç´¢å¼•ä¸­ O(1) æŸ¥æ‰¾ï¼Œä¸è§¦å‘æ•°æ®åº“æŸ¥è¯¢
        row_or = series_map.get((platform, org, repo, "openrank"))
        row_act = series_map.get((platform, org, repo, "activity"))

        if not row_or or not row_act:
            continue

        try:
            or_records = json.loads(row_or.data_json or "[]")
            act_records = json.loads(row_act.data_json or "[]")

            or_vals = _tail12_values(or_records)
            act_vals = _tail12_values(act_records)

            if not or_vals or not act_vals:
                continue

            openrank_mean_12m = _mean(or_vals)
            openrank_std_12m = _std_pop(or_vals)
            activity_mean_12m = _mean(act_vals)

            summary_items.append({
                "platform": platform,
                "org": org,
                "repo": repo,
                "project_key": repo_key,
                "category": category,
                "openrank_mean_12m": float(openrank_mean_12m),
                "openrank_std_12m": float(openrank_std_12m),
                "activity_mean_12m": float(activity_mean_12m),
            })
        except Exception:
            continue

    if not summary_items:
        raise ApiException(404, "æ•°æ®åº“ä¸­æ²¡æœ‰å¯ç”¨é¡¹ç›®æ•°æ®ï¼Œè¯·å…ˆè§¦å‘æ•°æ®åŒæ­¥ï¼ˆrun_syncï¼‰")

    # å½’ä¸€åŒ– + health_score
    max_or = max(i["openrank_mean_12m"] for i in summary_items) or 1.0
    max_act = max(i["activity_mean_12m"] for i in summary_items) or 1.0
    max_std = max(i["openrank_std_12m"] for i in summary_items) or 1.0

    for item in summary_items:
        or_norm = item["openrank_mean_12m"] / max_or if max_or > 0 else 0.0
        act_norm = item["activity_mean_12m"] / max_act if max_act > 0 else 0.0
        std_norm = item["openrank_std_12m"] / max_std if max_std > 0 else 0.0
        
        # ç¨³å®šæ€§ = 1 - æ³¢åŠ¨æ€§å½’ä¸€åŒ–å€¼
        stability_norm = 1.0 - std_norm

        # ä½¿ç”¨ç»Ÿä¸€çš„å¥åº·åº¦è®¡ç®—å‡½æ•°
        item["health_score"] = calculate_health_score(or_norm, act_norm, stability_norm)
        
        item["openrank_mean_12m"] = round(item["openrank_mean_12m"], 2)
        item["activity_mean_12m"] = round(item["activity_mean_12m"], 2)
        item["openrank_std_12m"] = round(item["openrank_std_12m"], 2)

    return summary_items

def get_llm_summary_cached(force: bool = False):
    if force:
        data = compute_llm_summary_from_db()
        _LLM_SUMMARY_CACHE["ts"] = datetime.utcnow()
        _LLM_SUMMARY_CACHE["data"] = data
        return data

    ts = _LLM_SUMMARY_CACHE["ts"]
    if ts and (datetime.utcnow() - ts).total_seconds() < LLM_CACHE_TTL_SECONDS:
        return _LLM_SUMMARY_CACHE["data"]

    data = compute_llm_summary_from_db()
    _LLM_SUMMARY_CACHE["ts"] = datetime.utcnow()
    _LLM_SUMMARY_CACHE["data"] = data
    return data

# ==== å®šä¹‰ Blueprint ====
api_bp = Blueprint("api", __name__, url_prefix="/api")


# ==== è‡ªå®šä¹‰å¼‚å¸¸ + ç»Ÿä¸€ JSON è¿”å› ====

class ApiException(Exception):
    """ç®€å•çš„ API å¼‚å¸¸ï¼šå¸¦ status_code å’Œ detail å­—æ®µ"""
    def __init__(self, status_code: int, detail: str):
        self.status_code = status_code
        self.detail = detail
        super().__init__(detail)


@api_bp.errorhandler(ApiException)
def handle_api_exception(e: ApiException):
    """è“å›¾çº§åˆ«çš„é”™è¯¯å¤„ç†ï¼šæŠŠ ApiException è½¬æˆ JSON"""
    return jsonify({"detail": e.detail}), e.status_code


# ==== å…¬å…±å·¥å…·å‡½æ•°ï¼šæŠ“å– & ç¼“å­˜ OpenDigger æ•°æ® ====

CACHE_TTL_HOURS = 24

def fetch_and_cache_data_db(api_url: str, platform: str, entity: str, repo: str | None, metric: str):
    repo_key = repo or ""  # â­ ç»Ÿä¸€ repo ä¸ºç©ºæ—¶å­˜ ""

    row = MetricSeries.query.filter_by(
        platform=platform, entity=entity, repo=repo_key, metric=metric
    ).first()

    # 1) å‘½ä¸­ç¼“å­˜ä¸”æœªè¿‡æœŸ
    if row and row.updated_at:
        if datetime.utcnow() - row.updated_at < timedelta(hours=CACHE_TTL_HOURS):
            if hasattr(row, "to_records"):
                return {"data": row.to_records(), "cached": True}
            return {"data": json.loads(row.data_json or "[]"), "cached": True}

    # 2) ç¼“å­˜æ²¡æœ‰/è¿‡æœŸï¼šè¯·æ±‚ OpenDiggerï¼ˆæŠŠä¸Šæ¸¸é”™è¯¯è½¬æˆ ApiExceptionï¼‰
    try:
        resp = requests.get(api_url, timeout=30, verify=False)
        resp.raise_for_status()
    except requests.HTTPError as e:
        code = getattr(e.response, "status_code", None)
        if code == 404:
            raise ApiException(404, "OpenDigger æ— è¯¥æŒ‡æ ‡æ•°æ®ï¼ˆ404ï¼‰")
        raise ApiException(502, f"OpenDigger ä¸Šæ¸¸ HTTP é”™è¯¯ï¼š{code}")
    except requests.RequestException as e:
        raise ApiException(502, f"è¯·æ±‚ OpenDigger å¤±è´¥ï¼š{e}")

    data = resp.json()
    if not isinstance(data, dict):
        raise ApiException(502, "OpenDigger è¿”å›æ ¼å¼å¼‚å¸¸ï¼ˆé dictï¼‰")

    formatted_data = [
        {"month": k, "count": v}
        for k, v in data.items()
        if isinstance(k, str) and len(k) == 7 and k.count("-") == 1
    ]
    if not formatted_data:
        raise ApiException(404, "æ— æœ‰æ•ˆæœˆåº¦æ•°æ®")

    payload = json.dumps(formatted_data, ensure_ascii=False)

    # 3) upsert å†™å› DBï¼ˆrepo ç”¨ repo_keyï¼‰
    if row:
        row.data_json = payload
    else:
        row = MetricSeries(
            platform=platform, entity=entity, repo=repo_key, metric=metric,
            data_json=payload
        )
        db.session.add(row)

    db.session.commit()
    return {"data": formatted_data, "cached": False}

    

# ===========================
# 1. å…ƒæ•°æ®ç›¸å…³æ¥å£ï¼ˆå¹³å° / å®ä½“ / æŒ‡æ ‡ / ä»“åº“ï¼‰
# ===========================

@api_bp.route("/platforms", methods=["GET"])
def get_platforms():
    """è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨"""
    return jsonify(meta.get_platforms())


@api_bp.route("/entities/<platform>", methods=["GET"])
def get_entities(platform: str):
    """è·å–æŸä¸ªå¹³å°ä¸‹çš„ç»„ç»‡/ç”¨æˆ·åˆ—è¡¨"""
    if not meta.is_supported_platform(platform):
        raise ApiException(400, f"ä¸æ”¯æŒçš„å¹³å°ï¼š{platform}")
    entities = meta.get_entities(platform)
    return jsonify(entities)


@api_bp.route("/metrics/<entity_type>", methods=["GET"])
def get_metrics(entity_type: str):
    """æ ¹æ®ç±»å‹ï¼ˆorg/userï¼‰è·å–æŒ‡æ ‡åˆ—è¡¨"""
    if entity_type not in ["org", "user"]:
        raise ApiException(400, f"æ— æ•ˆçš„ç±»å‹ï¼š{entity_type}ï¼Œä»…æ”¯æŒ org/user")
    metrics = meta.get_metrics(entity_type)
    return jsonify(metrics)


@api_bp.route("/repos/<platform>/<org>", methods=["GET"])
def get_repos(platform: str, org: str):
    """è·å–ç»„ç»‡ä¸‹çš„å¯æŸ¥è¯¢ä»“åº“åˆ—è¡¨ï¼ˆä»… org ç±»å‹å¯ç”¨ï¼‰"""
    if not meta.is_supported_platform(platform):
        raise ApiException(400, f"ä¸æ”¯æŒçš„å¹³å°ï¼š{platform}")
    if not meta.is_valid_entity(platform, org):
        raise ApiException(400, f"å¹³å° {platform} æ— è¯¥ç»„ç»‡ï¼š{org}")
    if meta.get_entity_type(platform, org) != "org":
        raise ApiException(400, f"{org} ä¸æ˜¯ç»„ç»‡ç±»å‹ï¼Œæ— ä»“åº“åˆ—è¡¨")

    repos = meta.get_repos(platform, org)
    if not repos:
        raise ApiException(404, "è¯¥ç»„ç»‡æš‚æ— å¯æŸ¥è¯¢çš„ä»“åº“")
    return jsonify(repos)


# ===========================
# 2. OpenDigger æŒ‡æ ‡æ•°æ®æ¥å£
# ===========================

@api_bp.route("/data/<platform>/<entity>/<metric>", methods=["GET"])
def get_user_data(platform: str, entity: str, metric: str):
    if not meta.is_supported_platform(platform):
        raise ApiException(400, "ä¸æ”¯æŒçš„å¹³å°")
    if not meta.is_valid_entity(platform, entity):
        raise ApiException(400, f"å¹³å° {platform} æ— è¯¥å®ä½“ï¼š{entity}")

    entity_type = meta.get_entity_type(platform, entity)
    if entity_type != "user":
        raise ApiException(400, f"è¯¥å®ä½“æ˜¯ {entity_type}ï¼Œè¯·ä½¿ç”¨ä»“åº“æ•°æ®æ¥å£")

    api_url = f"https://oss.open-digger.cn/{platform}/{entity}/{metric}.json"
    return jsonify(fetch_and_cache_data_db(api_url, platform, entity, None, metric))



@api_bp.route("/data/<platform>/<entity>/<repo>/<metric>", methods=["GET"])
def get_repo_data(platform: str, entity: str, repo: str, metric: str):
    if not meta.is_supported_platform(platform):
        raise ApiException(400, "ä¸æ”¯æŒçš„å¹³å°")

    api_url = f"https://oss.open-digger.cn/{platform}/{entity}/{repo}/{metric}.json"
    return jsonify(fetch_and_cache_data_db(api_url, platform, entity, repo, metric))



# ===========================
# 3. LLM æ±‡æ€» & æ’åæ¥å£
# ===========================

@api_bp.route("/llm/summary", methods=["GET"])
@rate_limit(max_requests=30, window_seconds=60) 
def get_llm_summary():
    # å¯é€‰ï¼šrefresh=1 å¼ºåˆ¶é‡æ–°è®¡ç®—ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰
    refresh = request.args.get("refresh", "0").lower() in ("1", "true", "yes")
    data = get_llm_summary_cached(force=refresh)
    return jsonify({"projects": data})



@api_bp.route("/llm/rank/<metric>", methods=["GET"])
@rate_limit(max_requests=30, window_seconds=60) 
def get_llm_rank(metric: str):
    allowed_metrics = {"health_score", "openrank_mean_12m", "activity_mean_12m"}
    if metric not in allowed_metrics:
        raise ApiException(400, f"ä¸æ”¯æŒçš„æ’åæŒ‡æ ‡: {metric}")

    top = request.args.get("top", default=10, type=int)
    refresh = request.args.get("refresh", "0").lower() in ("1", "true", "yes")

    data = get_llm_summary_cached(force=refresh)

    sorted_projects = sorted(
        data,
        key=lambda item: item.get(metric, 0.0),
        reverse=True
    )

    return jsonify({
        "metric": metric,
        "top": top,
        "projects": sorted_projects[:top]
    })



# ===========================
# 4. æ™ºèƒ½æŠ¥å‘Šæ¥å£ï¼ˆOpenAI + è§„åˆ™å…œåº•ï¼‰
# ===========================

@api_bp.route("/llm/report", methods=["POST"])
@rate_limit(max_requests=5, window_seconds=60)
def generate_llm_report():
    """
    æ ¹æ®å‰ç«¯ä¼ æ¥çš„é¡¹ç›®æŒ‡æ ‡ï¼Œç”Ÿæˆä¸€æ®µâ€œåˆ†æå¸ˆé£æ ¼â€çš„æ–‡å­—æŠ¥å‘Šã€‚
    è¯·æ±‚ä½“ç»“æ„ï¼š
      {
        "projects": [
          { "repo": "pytorch/pytorch", "metrics": { "activity": 0.8, ... } },
          ...
        ]
      }
    """
    payload = request.get_json(silent=True) or {}
    projects = payload.get("projects", [])

    if not projects:
        raise ApiException(400, "è‡³å°‘éœ€è¦ä¸€ä¸ªé¡¹ç›®")

    # 1) è®¡ç®—ç»¼åˆåˆ†
    enriched = []
    for p in projects:
        repo = p.get("repo", "unknown")
        metrics = p.get("metrics") or {}
        vals = list(metrics.values())
        score = sum(vals) / len(vals) if vals else 0.0
        enriched.append({"repo": repo, "metrics": metrics, "score": score})

    enriched.sort(key=lambda x: x["score"], reverse=True)

    # 2) æ•°å­—æ€»ç»“ï¼ˆç»™ LLM & è§„åˆ™æ¨¡æ¿ éƒ½ç”¨ï¼‰
    summary_lines = []
    for idx, p in enumerate(enriched, start=1):
        m = p["metrics"]
        summary_lines.append(
            f"{idx}. {p['repo']} â€”â€” æ€»ä½“å¾—åˆ†çº¦ {p['score']:.2f}ï¼Œ"
            f"æ´»è·ƒåº¦ {m.get('activity', 0):.2f}ï¼Œ"
            f"æ²»ç†è´¨é‡ {m.get('governance', 0):.2f}ï¼Œ"
            f"å¤šæ ·æ€§ {m.get('diversity', 0):.2f}ï¼Œ"
            f"LLM é€‚é…åº¦ {m.get('llm_fit', 0):.2f}ï¼Œ"
            f"å¯æŒç»­æ€§ {m.get('sustainability', 0):.2f}ã€‚"
        )
    numeric_summary = "\n".join(summary_lines)

    # 3) å¦‚æœé…ç½®äº† OpenAIï¼Œåˆ™è°ƒç”¨å¤§æ¨¡å‹å†™æŠ¥å‘Š
    if openai_client is not None:
        try:
            prompt = (
                "ä¸‹é¢æ˜¯ä¸€ç»„ LLM ç›¸å…³å¼€æºé¡¹ç›®åœ¨å¤šä¸ªç”Ÿæ€æŒ‡æ ‡ä¸Šçš„å½’ä¸€åŒ–å¾—åˆ†ï¼ˆ0~1ï¼‰ã€‚"
                "è¯·ä½ ç”¨ä¸­æ–‡å†™ä¸€æ®µ 3~5 æ®µè½çš„åˆ†æå¸ˆé£æ ¼æŠ¥å‘Šï¼Œ"
                "æ€»ç»“è°æ›´å¼ºã€å„è‡ªçš„ä¼˜åŠ¿çŸ­æ¿ï¼Œä»¥åŠå¯èƒ½çš„ç¤¾åŒºæ¼”åŒ–è¶‹åŠ¿ã€‚"
                "æ³¨æ„é¢å‘éæŠ€æœ¯è¯„å§”ï¼Œè¯­è¨€æ¸…æ™°ã€ç»“æ„æœ‰å°æ ‡é¢˜ã€‚\n\n"
                f"{numeric_summary}"
            )

            # å®šä¹‰æ›´æ™ºèƒ½çš„ System Prompt
            system_prompt = """
ä½ æ˜¯ä¸€åè´Ÿè´£å¼€æºç”Ÿæ€è¯„ä¼°çš„èµ„æ·±åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æ•°æ®å†™ä¸€ä»½æ·±åº¦å¯¹æ¯”æŠ¥å‘Šã€‚

ã€å†…å®¹ä¸æ ¼å¼è¦æ±‚ã€‘ï¼š
1. **ç»“æ„å¿…é¡»æ¸…æ™°**ï¼šæŠ¥å‘Šå¿…é¡»åŒ…å« 3-4 ä¸ªæ˜ç¡®çš„ Markdown å°æ ‡é¢˜ï¼ˆä½¿ç”¨ ### è¯­æ³•ï¼‰ï¼Œä¾‹å¦‚ï¼š
   ### ğŸ“Š æ€»ä½“è¯„åˆ†æ¦‚è§ˆ
   ### ğŸš€ å„é¡¹ç›®æ ¸å¿ƒä¼˜åŠ¿
   ### âš ï¸ æ½œåœ¨é£é™©ä¸çŸ­æ¿
   ### ğŸ”® ç¤¾åŒºæ¼”åŒ–è¶‹åŠ¿

2. **é‡ç‚¹çµæ´»é«˜äº®**ï¼š
   - è¯·è¯†åˆ«æŠ¥å‘Šä¸­çš„ **å…³é”®ç»“è®ºã€æ ¸å¿ƒæ•°æ®å¯¹æ¯”ã€æˆ–çŠ€åˆ©çš„æ´å¯Ÿ**ã€‚
   - å°†è¿™äº›å¥å­ç”¨ Markdown åŠ ç²—ç¬¦å·ï¼ˆ**...**ï¼‰åŒ…è£¹ã€‚
   - âš ï¸ ä¸éœ€è¦å±€é™äºæ®µè½å¼€å¤´ï¼Œå“ªé‡Œé‡è¦å°±æ ‡å“ªé‡Œï¼Œä½†ä¸è¦å…¨æ–‡é€šç¯‡åŠ ç²—ã€‚

3. **ç»“å°¾å¼ºåˆ¶æ€»ç»“**ï¼š
   - æŠ¥å‘Šçš„æœ€åï¼Œå¿…é¡»åŒ…å«ä¸€ä¸ª Markdown å¼•ç”¨å—ï¼ˆä½¿ç”¨ > ç¬¦å·ï¼‰ã€‚
   - å†…å®¹å¿…é¡»ä»¥ â€œğŸ’¡ **åˆ†æå¸ˆå»ºè®®ï¼š**â€ å¼€å¤´ï¼Œé’ˆå¯¹ä¸åŒåœºæ™¯ç»™å‡º 1-2 å¥å…·ä½“çš„é€‰å‹å»ºè®®ã€‚
   - æ ¼å¼ç¤ºä¾‹ï¼š
     > ğŸ’¡ **åˆ†æå¸ˆå»ºè®®ï¼š** å¦‚æœè¿½æ±‚ç¨³å®šæ€§ï¼Œæ¨èé€‰æ‹© PyTorchï¼›å¦‚æœéœ€è¦å¿«é€ŸéªŒè¯ Agentï¼ŒLangChain æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚

4. **è¯­æ°”é£æ ¼**ï¼šä¸“ä¸šã€å®¢è§‚ã€è§è§£ç‹¬åˆ°ã€‚
"""

            # ä¸‹é¢è¿™éƒ¨åˆ†ä¿æŒä¸å˜
            resp = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.5,
            )
            content = resp.choices[0].message.content
            return jsonify({"report": content, "from_llm": True})
        except Exception as e:
            print("è°ƒç”¨ LLM å¤±è´¥ï¼Œå°†ä½¿ç”¨è§„åˆ™æ¨¡æ¿ï¼š", e)
    

    # 4) å…œåº•æ¨¡æ¿
    text_lines = [
        "ã€LLM é¡¹ç›®ç”Ÿæ€æ¦‚è§ˆã€‘",
        "åŸºäºæœ€è¿‘ 12 ä¸ªæœˆçš„å¼€æºæ´»åŠ¨æ•°æ®ï¼Œæˆ‘ä»¬å¯¹å½“å‰é€‰æ‹©çš„ LLM ç›¸å…³é¡¹ç›®è¿›è¡Œäº†äº”ç»´åº¦çš„ç”Ÿæ€å¥åº·åº¦è¯„ä¼°ã€‚",
        "",
        "ä¸€ã€ç»¼åˆå¾—åˆ†æ’åº",
        numeric_summary,
        "",
        "äºŒã€æ•´ä½“è§‚å¯Ÿ",
        "ä»å¾—åˆ†æƒ…å†µå¯ä»¥çœ‹å‡ºï¼Œæ’åé å‰çš„é¡¹ç›®åœ¨æ´»è·ƒåº¦å’Œæ²»ç†è´¨é‡ä¸Šæ™®éè¡¨ç°è¾ƒå¥½ï¼Œè¯´æ˜ç¤¾åŒºæœ‰ç¨³å®šçš„è´¡çŒ®è€…ç¾¤ä½“ä»¥åŠè¾ƒå®Œå–„çš„åä½œæµç¨‹ã€‚",
        "å¾—åˆ†ç›¸å¯¹åä½çš„é¡¹ç›®ï¼Œé€šå¸¸é›†ä¸­å‡ºç°åœ¨å¤šæ ·æ€§æˆ–å¯æŒç»­æ€§ç»´åº¦ï¼Œå¯èƒ½æ„å‘³ç€è´¡çŒ®è€…ç»“æ„è¾ƒé›†ä¸­ï¼Œæˆ–è€…æ ¸å¿ƒç»´æŠ¤è€…è¿‡äºå°‘æ•°åŒ–ã€‚",
        "",
        "ä¸‰ã€ç®€å•å»ºè®®",
        "å¯¹äºç»¼åˆå¾—åˆ†è¾ƒé«˜çš„é¡¹ç›®ï¼Œå¯ä»¥è¿›ä¸€æ­¥å…³æ³¨å¦‚ä½•æå‡æ–°è´¡çŒ®è€…çš„è¿›å…¥ä½“éªŒï¼Œå·©å›ºå¤šæ ·æ€§ä¼˜åŠ¿ï¼›",
        "å¯¹äºå¾—åˆ†åä½çš„é¡¹ç›®ï¼Œåˆ™å»ºè®®åœ¨æ–‡æ¡£å®Œå–„ã€Issue åé¦ˆå“åº”ä»¥åŠç¤¾åŒºè¿è¥ç­‰æ–¹é¢æŠ•å…¥æ›´å¤šç²¾åŠ›ï¼Œä»¥æå‡é•¿æœŸçš„å¯æŒç»­å‘å±•èƒ½åŠ›ã€‚"
    ]
    return jsonify({"report": "\n".join(text_lines), "from_llm": False})

# ===========================
# LLM é¡¹ç›®æ ‘æ¥å£ï¼ˆæ–°å¢ï¼‰
# ===========================

@api_bp.route("/llm/projects", methods=["GET"])
def get_llm_projects():
    """
    è¿”å› LLM ç”Ÿæ€çš„é¡¹ç›®æ ‘ç»“æ„ï¼ˆç”¨äºå‰ç«¯é€‰æ‹©æ¡†ï¼‰
    ä» config.json çš„ category_tree å­—æ®µè¯»å–ï¼Œå¹¶è¿‡æ»¤æ‰ä¸åœ¨ repositories ä¸­çš„é¡¹ç›®
    """
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            config = json.load(f)
        
        category_tree = config.get("category_tree", [])
        if not category_tree:
            raise ApiException(404, "é…ç½®æ–‡ä»¶ä¸­æœªå®šä¹‰ category_tree")
        
        # è·å–æœ‰æ•ˆé¡¹ç›®åˆ—è¡¨ï¼ˆorg/repo æ ¼å¼ï¼‰
        valid_repos = {
            f"{r['org']}/{r['repo']}" 
            for r in config.get("repositories", [])
        }
        
        # è¿‡æ»¤æ ‘ç»“æ„ï¼Œç§»é™¤æ— æ•ˆé¡¹ç›®
        def filter_tree(nodes):
            result = []
            for node in nodes:
                if "children" in node and node["children"]:
                    # éå¶å­èŠ‚ç‚¹ï¼šé€’å½’è¿‡æ»¤å­èŠ‚ç‚¹
                    filtered_children = filter_tree(node["children"])
                    if filtered_children:  # åªä¿ç•™æœ‰å­èŠ‚ç‚¹çš„åˆ†ç±»
                        result.append({
                            **node,
                            "children": filtered_children
                        })
                else:
                    # å¶å­èŠ‚ç‚¹ï¼šæ£€æŸ¥æ˜¯å¦åœ¨æœ‰æ•ˆåˆ—è¡¨ä¸­
                    if node.get("value") in valid_repos:
                        result.append(node)
            return result
        
        filtered_tree = filter_tree(category_tree)
        
        return jsonify({
            "tree": filtered_tree,
            "total_projects": len(valid_repos)
        })
    except FileNotFoundError:
        raise ApiException(500, "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    except json.JSONDecodeError:
        raise ApiException(500, "é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯")

# ===========================
# 5. è´¡çŒ®è€…å¥åº·é¢„è­¦ç³»ç»Ÿï¼ˆåˆ›æ–°åŠŸèƒ½ï¼‰
# ===========================

@api_bp.route("/health/contributor-risk/<platform>/<org>/<repo>", methods=["GET"])
@rate_limit(max_requests=30, window_seconds=60)
def get_contributor_risk(platform: str, org: str, repo: str):
    """
    è´¡çŒ®è€…é›†ä¸­åº¦é£é™©åˆ†æ API
    
    åŸºäº bus_factorï¼ˆå·´å£«å› å­ï¼‰æŒ‡æ ‡åˆ¤æ–­é¡¹ç›®æ˜¯å¦è¿‡åº¦ä¾èµ–å°‘æ•°å¼€å‘è€…
    å·´å£«å› å­ = æœ€å°‘éœ€è¦å¤šå°‘æ ¸å¿ƒå¼€å‘è€…"è¢«å·´å£«æ’äº†"é¡¹ç›®æ‰ä¼šåœæ»
    
    Returns:
        {
            "project": "pytorch/pytorch",
            "bus_factor_avg_6m": 8.5,
            "bus_factor_trend": "stable",
            "risk_level": "low",
            "risk_score": 0.15,
            "message": "âœ… å¥åº·ï¼šé¡¹ç›®æœ‰è¶³å¤Ÿçš„è´¡çŒ®è€…å†—ä½™",
            "suggestion": null,
            "details": {...}
        }
    """
    api_url = f"https://oss.open-digger.cn/{platform}/{org}/{repo}/bus_factor.json"
    
    try:
        result = fetch_and_cache_data_db(api_url, platform, org, repo, "bus_factor")
        records = result["data"]
        
        if not records:
            raise ApiException(404, "è¯¥é¡¹ç›®æš‚æ—  bus_factor æ•°æ®")
        
        # å–æœ€è¿‘ 6 ä¸ªæœˆå’Œ 12 ä¸ªæœˆçš„æ•°æ®åšå¯¹æ¯”
        recent_6m = _tail12_values(records)[-6:] if len(_tail12_values(records)) >= 6 else _tail12_values(records)
        recent_12m = _tail12_values(records)
        
        avg_6m = _mean(recent_6m) if recent_6m else 0
        avg_12m = _mean(recent_12m) if recent_12m else 0
        
        # è®¡ç®—è¶‹åŠ¿
        if len(recent_6m) >= 2:
            first_half = _mean(recent_6m[:len(recent_6m)//2])
            second_half = _mean(recent_6m[len(recent_6m)//2:])
            if second_half > first_half * 1.1:
                trend = "improving"
                trend_text = "ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿"
            elif second_half < first_half * 0.9:
                trend = "declining"
                trend_text = "ğŸ“‰ ä¸‹é™è¶‹åŠ¿"
            else:
                trend = "stable"
                trend_text = "â¡ï¸ ä¿æŒç¨³å®š"
        else:
            trend = "unknown"
            trend_text = "â“ æ•°æ®ä¸è¶³"
        
        # é£é™©ç­‰çº§åˆ¤å®š
        if avg_6m <= 1.5:
            risk_level = "critical"
            risk_score = 0.95
            message = "ğŸ”´ æé«˜é£é™©ï¼šé¡¹ç›®å‡ ä¹å®Œå…¨ä¾èµ–å•ä¸€å¼€å‘è€…ï¼"
            suggestion = "å»ºè®®ç«‹å³å…³æ³¨ï¼šè¯¥é¡¹ç›®éšæ—¶å¯èƒ½å› æ ¸å¿ƒå¼€å‘è€…ç¦»å¼€è€Œåœæ»ã€‚å¦‚ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œè¯·å‡†å¤‡æ›¿ä»£æ–¹æ¡ˆã€‚"
        elif avg_6m <= 3:
            risk_level = "high"
            risk_score = 0.75
            message = "ğŸŸ  é«˜é£é™©ï¼šé¡¹ç›®ä¸¥é‡ä¾èµ– 1-3 ä½æ ¸å¿ƒå¼€å‘è€…"
            suggestion = "å»ºè®®è°¨æ…ï¼šè¯¥é¡¹ç›®æ ¸å¿ƒè´¡çŒ®è€…è¿‡äºé›†ä¸­ã€‚å…³æ³¨ç¤¾åŒºæ˜¯å¦æœ‰æ–°è´¡çŒ®è€…åŸ¹å…»è®¡åˆ’ã€‚"
        elif avg_6m <= 5:
            risk_level = "medium"
            risk_score = 0.45
            message = "ğŸŸ¡ ä¸­é£é™©ï¼šæ ¸å¿ƒå¼€å‘è€…æ•°é‡åå°‘"
            suggestion = "å»ºè®®å…³æ³¨ï¼šå¯æŸ¥çœ‹é¡¹ç›®çš„ CONTRIBUTING.md å’Œç¤¾åŒºæ´»è·ƒåº¦ï¼Œè¯„ä¼°é•¿æœŸå¯æŒç»­æ€§ã€‚"
        elif avg_6m <= 8:
            risk_level = "low"
            risk_score = 0.2
            message = "ğŸŸ¢ ä½é£é™©ï¼šé¡¹ç›®æœ‰è¾ƒå¥½çš„è´¡çŒ®è€…åˆ†å¸ƒ"
            suggestion = None
        else:
            risk_level = "healthy"
            risk_score = 0.05
            message = "âœ… éå¸¸å¥åº·ï¼šé¡¹ç›®æœ‰å……è¶³çš„è´¡çŒ®è€…å†—ä½™"
            suggestion = None
        
        # å¦‚æœè¶‹åŠ¿ä¸‹é™ï¼Œæé«˜é£é™©åˆ†æ•°
        if trend == "declining" and risk_level not in ["critical", "high"]:
            risk_score = min(risk_score + 0.15, 0.9)
            message += "ï¼ˆâš ï¸ æ³¨æ„ï¼šè´¡çŒ®è€…é›†ä¸­åº¦æ­£åœ¨æ¶åŒ–ï¼‰"
        
        return jsonify({
            "project": f"{org}/{repo}",
            "platform": platform,
            "bus_factor_avg_6m": round(avg_6m, 2),
            "bus_factor_avg_12m": round(avg_12m, 2),
            "bus_factor_trend": trend,
            "bus_factor_trend_text": trend_text,
            "risk_level": risk_level,
            "risk_score": round(risk_score, 2),
            "message": message,
            "suggestion": suggestion,
            "details": {
                "recent_values": [round(v, 2) for v in recent_6m],
                "min_6m": round(min(recent_6m), 2) if recent_6m else 0,
                "max_6m": round(max(recent_6m), 2) if recent_6m else 0,
            },
            "cached": result.get("cached", False)
        })
        
    except ApiException:
        raise
    except Exception as e:
        raise ApiException(500, f"åˆ†æè´¡çŒ®è€…é£é™©å¤±è´¥: {str(e)}")


@api_bp.route("/health/batch-risk", methods=["POST"])
@rate_limit(max_requests=10, window_seconds=60)
def get_batch_contributor_risk():
    """
    æ‰¹é‡è·å–å¤šä¸ªé¡¹ç›®çš„è´¡çŒ®è€…é£é™©ï¼ˆç”¨äºå¯¹æ¯”é¡µé¢ï¼‰
    
    è¯·æ±‚ä½“ï¼š
    {
        "projects": ["pytorch/pytorch", "huggingface/transformers"]
    }
    """
    data = request.get_json(silent=True) or {}
    projects = data.get("projects", [])
    
    if not projects:
        raise ApiException(400, "è¯·æä¾›è‡³å°‘ä¸€ä¸ªé¡¹ç›®")
    
    if len(projects) > 10:
        raise ApiException(400, "å•æ¬¡æœ€å¤šæŸ¥è¯¢ 10 ä¸ªé¡¹ç›®")
    
    results = []
    
    for proj in projects:
        parts = proj.strip().split("/")
        if len(parts) != 2:
            results.append({
                "project": proj,
                "error": "æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º org/repo"
            })
            continue
        
        org, repo = parts
        api_url = f"https://oss.open-digger.cn/github/{org}/{repo}/bus_factor.json"
        
        try:
            result = fetch_and_cache_data_db(api_url, "github", org, repo, "bus_factor")
            records = result["data"]
            recent_6m = _tail12_values(records)[-6:] if records else []
            avg_6m = _mean(recent_6m) if recent_6m else 0
            
            # ç®€åŒ–çš„é£é™©åˆ¤å®š
            if avg_6m <= 2:
                risk_level, risk_score = "high", 0.8
            elif avg_6m <= 5:
                risk_level, risk_score = "medium", 0.5
            else:
                risk_level, risk_score = "low", 0.2
            
            results.append({
                "project": proj,
                "bus_factor_avg_6m": round(avg_6m, 2),
                "risk_level": risk_level,
                "risk_score": round(risk_score, 2)
            })
        except Exception as e:
            results.append({
                "project": proj,
                "error": str(e)
            })
    
    return jsonify({"results": results})